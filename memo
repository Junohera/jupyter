-------------------------------------------------------------
vectorization - 동시계산
cpu
-------------------------------------------------------------
array = numnpy format
-------------------------------------------------------------
numpy단점 gpu 미지원
--> tensor는 gpu로 지원해줌.
-------------------------------------------------------------
numpy format
	- sequence
	- immutable
	- homor
-------------------------------------------------------------
데이터저장하는 방식 세가지
python
c
portlan?
-------------------------------------------------------------
shape, dtype만 알고있으면 나머지 유추가능
-------------------------------------------------------------
shape이 같아야만 연산이가능
-------------------------------------------------------------
dtype
데이터 공간 ex) db 또는 c
-------------------------------------------------------------
ndim
차원
-------------------------------------------------------------
size
원소의 개수
-------------------------------------------------------------
itemsize = dtype/8
-------------------------------------------------------------
python의 list내부구조가
메모리가 비어있는 순서대로 저장 -> 이중구조 -> 인덱싱하는데 여러번 일을 수행함. + 데이터타입, 위치 체크

그러나, numpy Array는 한열로 저장하고, 데이터타입동일하기때문에 -> 인덱싱하는데 최소한의 일만 수행함.
-------------------------------------------------------------
strides (=pointer)
1칸에 4Byte, 1줄에 12Byte
-------------------------------------------------------------
loop연산속도
numpy vectorize > map function > list comprehonsion > plain forLoop
-------------------------------------------------------------

array([[ 0,  1,  2,  3],
       [ 4,  5,  6,  7],
       [ 8,  9, 10, 11]])

x[[True, True, False], [False, False, True, True]] # True인 행과 True인 열

-------------------------------------------------------------
axis
axis = 0 열마다
axis = 1 행마다
axis = None 전체

-------------------------------------------------------------
numpy 도움말 보기
1. np.info(np.sum) - 
2. np.lookfor('sum') - 문자열 포함된 모든 목록 찾아줌
-------------------------------------------------------------
?.shape
(x, y, z)
size, height, width
-------------------------------------------------------------
데이터 저장방식
대부분 C이나 간혹 포트란
c : 
1 2 3 4
5 6 7 8 
포트란 :
1 3 5 7
2 4 6 8
-------------------------------------------------------------
Multidimensional Arrays
ndarray
-------------------------------------------------------------
%whos ndarray # ndarray만 찾기 (numpy.ndarray)
-------------------------------------------------------------
uint16 (=unsigned )
-------------------------------------------------------------
영상, 이미지는 int16(for 256), 금융은 float64
-------------------------------------------------------------
ufunc (=universal Functions)

%time reduce(lambda x, y : x + y, range(100_000))
CPU times: user 12.7 ms, sys: 0 ns, total: 12.7 ms
Wall time: 12.2 ms
4999950000

%time np.add.reduce(np.arange(100_000))
CPU times: user 1.1 ms, sys: 0 ns, total: 1.1 ms
Wall time: 500 µs
4999950000

%time np.sum(np.arange(100_000))
CPU times: user 959 µs, sys: 311 µs, total: 1.27 ms
Wall time: 641 µs
4999950000

-------------------------------------------------------------
mean 평균
accumulate 누적합
-------------------------------------------------------------
차원끼리 연산하기위해서는 서로 모양이 같아야한다.
하지만 보정해주는 경우가 있는데 이를 활용한 기법이, broadcasting기법

# broadcasting

# 1.  
np.array([[1,2],[3,4]]) + 1

# 2. shape에 1만 있을경우. 크기 보정
np.array([[1,2],[3,4]]) + np.array([[4,5]])

# 3. 2와는 반대로
np.array([[1,2],[3,4]]) + np.array([[10],[10]])

# example
iris['petal_length'] + 10 # broadcasting
-------------------------------------------------------------
수동으로 맞추는방법 - 

1. reshape - 원본미접근, 모양기준, 2차로 변경되기도함.

# 수동으로 맞춰주는법
a = np.arange(10)
a = a.reshape(2, -1) # 모든 음수값은 가능하나 관례상 -1

2. resize - 원본접근, 갯수기준

3. ravel - view

4. flatten - copy
  
5. squeeze - 차원 축소

6. expand_dims - 차원 확대

7. newaxis - 
-------------------------------------------------------------
strides를 변경해도 가능
-------------------------------------------------------------
pickle
직렬화 기법
일반 텍스트가 아닌 데이터형을 유지한채 저장하는 방식
-------------------------------------------------------------
r_ : !callable
ix_ : callable
-------------------------------------------------------------
pandas 활용법 두가지
	- 1. EDA (Exploratory Data Analysis) 탐색적 데이터 분석
	- 2. 기계학습을 위한 전처리


-------------------------------------------------------------
numpyFormat
	- 1. pd.DataFrame(numpyFormat) # convert dataFrame
	- 2. pd.read_???
-------------------------------------------------------------
dataFrame 2열이상
	- 인덱스와 헤더가 존재하는 
	- .values하면 numpy포맷으로 변경
	- 2차원	
-------------------------------------------------------------
series 1열
	- .values하면 numpy포맷으로 변경
	- 1차원
-------------------------------------------------------------

열로 추출 - dictionary방식

b['사고년도']
-------------------------------------------------------------
.으로 접근.
dictionary방식 말고 (=data['column']) .방식도있음.
단, 특문이나 numpy의 키워드랑 겹치면안된다.
-------------------------------------------------------------
 (numpy syntax)
b.describe() # summary
b.describe().T #  열과 행 바꾸기 .T

-------------------------------------------------------------
데이터프레임 가져오면 하는것
1. .info()
2. describe() - include값이 기본적으로 숫자만 되어있으므로
-------------------------------------------------------------
loc는 이름으로
iloc는 순수 인덱스번호로
-------------------------------------------------------------
pancy indexing
	iris[iris.columns[:-1]] # pancy indexing
-------------------------------------------------------------
inplace - 그대로 적용을 시킬지의 여부(원본수정)
-------------------------------------------------------------
pandas에서는 index가 X축
-------------------------------------------------------------
# 컬럼추출방법 3가지

	# 1. series
	tips['tip'] 	

	# 2. dataFrame
	tips[['tip']] 

	# 3. 프로퍼티로접근
	tips.tip 
-------------------------------------------------------------
unique
	tips['day'].unique() # 서로다른 갯수
-------------------------------------------------------------
predicate함수

	boolean반환하는 함수
	bool이 왜 True|False 인데, 숫자 1과 0으로 취급되는가 ?
	상속받았는지 여부 확인하기.로 확인가능
	issubclass(bool, int)
-------------------------------------------------------------
시각화해서 보기 ( info, describe 보완 ) 

	mpg.boxplot()

-------------------------------------------------------------
상관계수 
data.corr()

# 색이 진하면 진할수록 음의 상관관계, 색이 옅을수록 양의 상관관계
sns.heatmap(mpg.corr()) # 색분포도로 데이터간 상관관계를 visualization화하여 보는 법
-------------------------------------------------------------
when import data

	1. head - 머리에서 데이터 추출

	2. tail - 바닥에서 데이터 추출

	3. sample - n개만큼 랜덤한 데이터 추출
-------------------------------------------------------------
graph그리기 
대상데이터.plot.원하는그래프형태()
-------------------------------------------------------------
기본적으로 세팅하는 라이브러리

	import numpy as np
	import matplotlib.pyplot as plt
	import pandas as pd
	import seaborn as sns
-------------------------------------------------------------
스타일을 바꾸게되면
	pandas가 plt에 의존하고있어서 pandas도 같이 바뀜
		plt.style.available # 사용가능한 스타일 목록조회
		plt.style.use('ggplot') # 사용하고싶은 스타일 세팅


	history
		from sadf import * # 편하긴하나 무겁.
		import matplotlib.pylab as plt # pylab이 가벼우나 공식홈페이지에서도 지양하는 방법
		import matplotlib.pyplot as plt # 결국 이걸로 사용
-------------------------------------------------------------
그래프수정하기 - State Machine기법 개념 이해해야함.

	plt.figure(figsize=(10, 5))
	plt.axes()
	plt.hist([1,2,1,2,3,4])
	plt.title('Title'); # 제목
	plt.xticks([1,2,3]); # x축 
	plt.yticks([1,3,5,7]); # y축
	plt.xlim([1,2]) # x범위 지정
	plt.ylim([1,2]) # y범위 지정
	plt.xlabel('xTicks Name') # x축 이름
	plt.ylabel('yTicks Name') # y축 이름

-------------------------------------------------------------

# 한글적용하기
	import matplotlib

	폰트리스트 확인
		fm = matplotlib.font_manager.FontManager()
		# fm.ttflist # 현재 컴퓨터에서 사용가능한 폰트리스트 확인
		# <Font 'Noto Sans CJK JP' (NotoSansCJK-Thin.ttc) normal normal 400 normal>

	폰트 적용
		plt.rcParams['font.family'] = 'Noto Sans CJK JP' # 한글 지원하는 폰트로 설정
	
-------------------------------------------------------------
%lsmagic # jupyter에서 지원하는 매직펑션 확인

%matplotlib notebook # 팝업처럼나옴, 물론 현재 os설정에 따라 달라지기도함.
%matplotlib inline # 기본값(=노잼)
-------------------------------------------------------------
pd.read_csv
	header : 헤더 여부

	sep : 구분자
-------------------------------------------------------------
pandas 컬럼 지우기

drop

# data.drop(1, axis=1, inplace=True)
-------------------------------------------------------------
encoding Error 대응

	 Error tokenizing data. C error: Expected 1 fields in line 12, saw 3

	 engine='python' ||
	 sep='|' ||
	 encoding= isEng & 'latin1' || isKo & 'cp949'
-------------------------------------------------------------
pandas 필수 세가지

	aggregation

		groupby
			1. split
				특정 컬럼으로 쪼갬
				
			2. apply
				.mean
				.count
				.max
				.min

			3. combine
				2를 다시 합쳐줌
		pivot
			합쳐서 표현하는게 아니라 단건단건 점찍어서 표현?
		crosstab
-------------------------------------------------------------
!tidy(=wide) -> melt() -> tidy

id_vars : 변경하지 않을 값
-------------------------------------------------------------
데이터 분석 기본 프로세스

	1. import data
	2. isTidy(data) ? 
-------------------------------------------------------------
컬럼명 변경
-------------------------------------------------------------
인덱스만 추출
.index
컬럼만 추출
.column
-------------------------------------------------------------
NaN값 지우기

dropna() 
-------------------------------------------------------------
합치기
	stack
	concat
		pd.concat([a,c], axis=1) # a와 c를 concatnate
-------------------------------------------------------------
default setting

import folium
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

plt.style.use('ggplot')
plt.rcParams['font.family'] = 'Noto Sans CJK JP'

-------------------------------------------------------------
pandas.wide_to_long(data)
melt나오기전에 유일한 방법인데, 쓰기 어려움..., 형태를 완벽하게 맞춰야하는 번거로움이 존재.
범용적으로는 melt를 이용하지만, 알고는 있으셈! 
-------------------------------------------------------------
reset_index
	
-------------------------------------------------------------
jupyter notebook theme
pip install jupyterthemes

available list	
	jt - l

set theme
	jt - t ??
-------------------------------------------------------------
지도 벡터 표현방식 두가지
in Web
topo_json geo_json
-------------------------------------------------------------
from pprint import pprint
pretty 
-------------------------------------------------------------
import time
	시각

현재시각
timestamp :from 1970-01-01

현재로컬시각
localTime = time.localtime()

	# 달로 접근`하기
	localTime.tm_mon # dic
	localTime[1]` # list
-------------------------------------------------------------
import calendar
	달력 찍어주는애
-------------------------------------------------------------
import datetime
	

	import datetime

	x = datetime.date(2019, 11, 27)

	x.year # o
	# x['year']  x
	# x[0] x
-------------------------------------------------------------
인덱스 2개

new_dat스.set_index(['Date', 'forecast']) # 동시에 2개 인덱스

-------------------------------------------------------------
stack (melt와 비슷, melt가 좀더 간편)
	컬럼에 있는 값을 인덱스로 변경
-------------------------------------------------------------
stack과 unstack을 이용해서 원하는대로 구조변경가능

-------------------------------------------------------------
duplicated
	중복체크
	반대는 dropduplicated?
-------------------------------------------------------------
귀여운 그래프스타일
1 plt.xkcd()
2 plt.style.use('ggplot')

plt.rcdefaults() # 초기화

한번만 귀여운스타일
with plt.xkcd():
    tips[['tip']].plot.bar()
-------------------------------------------------------------
1. read_csv
2. tidy_data
	melt
	set_index, stack
	wide_to_long
3. info
	data-type
	head
	miss

4.
5.d

-------------------------------------------------------------
df['column'].value_counts()
	해당 컬럼의 값 갯수 # df(DataFrame)의 column이란 컬럼의 값 갯수
-------------------------------------------------------------
DataFrame에서 
	map
		- only series
		t['petal length (cm)'] = t['petal length (cm)'].map(lambda x:x+1) # map series에서만 사용 가능
	apply
		- series & DataFrame
		- axis, reduce도 포함되어있음.
		t['petal length (cm)'] = t['petal length (cm)'].apply(lambda x:x+1) # apply series&DataFrame 사용 가능
	applymap
		- only DataFrame
-------------------------------------------------------------
데이터범위 지정하고싶을때 사용
	a = np.array([1,2,3,4,5,6,7])
	np.clip(a, 2,5)  # 2 if 2>x elif 5<x 5, 2보다 작으면 2 5보다 크면 5(=fix range(2to5))
	# array([2, 2, 3, 4, 5, 5, 5])
-------------------------------------------------------------
비정형 데이터에서 가장 성능이 좋음.
굳이 인공지능이 아니더라도 똑같이 꾸릴 수있으나,,
가격과 성능을 비교하여 인공지능을 대입할지 

Data로부터 Specific 문제 해결을 위한 최적의 모델 만들기.
Data(비정형데이터 ex: 자연어, 이미지, 영상...)
Specific(매우 협소한 특정 기능, 특정분야 한가지만 가능. 여러가지 동시에 하지못함. 기존에 존재하던 기술을 기반으로 ... 한두가지정도)

기계학습 : 정형데이터가 성능이 좋음.
딥러닝 : 정형데이터도 활용가능하긴함... 그러나...비정형데이터가 성능이 좋음
-------------------------------------------------------------
인공지능의 시작은 
데이터 ==> pandas

가용한 데이터인지 알수 있으려면, 
	1. EDA(비쥬얼라이제이션을 통해 데이터에 대한 빠른 분석) Exploratory Data Analysis
	2. 데이터 전처리(정제) 
그리고 쉽게 정제하기위함. ==> pandas

기계학습의 성능: 알고리즘 < 데이터
-------------------------------------------------------------
인공지능 : 데이터 분석 = 기존 IT : 요구사항 분석

-------------------------------------------------------------
seaborn = 간편하게 그래프출력 + 연습용 데이터
import seaborn as sns # 통계적 그래프를 간단하게 그려줌.
-------------------------------------------------------------
from sklearn.datasets import 
	1. load 작은데이터
	2. fetch 웹데이터
	3. make 랜덤데이터
-------------------------------------------------------------
컬럼 feature || dimension || x값

-------------------------------------------------------------
리그레이션
클래스피케이션?
-------------------------------------------------------------
기계학습은 반드시 숫자여야만함. (= 인코딩)
통계에 의존성이 큼. (성능과 연관 깊음.)
-------------------------------------------------------------
sns.pairplot = 그려놓고 시작

	sns.pairplot(iris.iloc[:, :-1]) # data는 pandas여야함! 4 x 4 = 16, 16개 출력
		# 그래프 그리기 1. 
	sns.pairplot(iris, vars=iris.columns[:-1], hue='target') # data는 pandas여야함! 4 x 4 = 16, 16개 출력
		# 그래프 그리기 2. hue는 색깔, vars는 사용할 데이터 (= hue에는 'target'은 써야하지만, 그래프에 출력시키면 안되므로..)

-------------------------------------------------------------
ready 4 edu
	x_train, x_test, y_train, y_test = train_test_split(iris.iloc[:,:-1], iris.target)  # x = 0~4줄, y = 1줄, target, label, class값

-------------------------------------------------------------
classifier
regression 
	선형 회귀(線型回歸, 영어: linear regression)는 종속 변수 y와 한 개 이상의 독립 변수 (또는 설명 변수) X와의 선형 상관 관계를 모델링하는 회귀분석 기법
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
