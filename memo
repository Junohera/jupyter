-------------------------------------------------------------
vectorization - 동시계산
cpu
-------------------------------------------------------------
array = numnpy format
-------------------------------------------------------------
numpy단점 gpu 미지원
--> tensor는 gpu로 지원해줌.
-------------------------------------------------------------
numpy format
	- sequence
	- immutable
	- homor
-------------------------------------------------------------
데이터저장하는 방식 세가지
python
c
portlan?
-------------------------------------------------------------
shape, dtype만 알고있으면 나머지 유추가능
-------------------------------------------------------------
shape이 같아야만 연산이가능
-------------------------------------------------------------
dtype
데이터 공간 ex) db 또는 c
-------------------------------------------------------------
ndim
차원
-------------------------------------------------------------
size
원소의 개수
-------------------------------------------------------------
itemsize = dtype/8
-------------------------------------------------------------
python의 list내부구조가
메모리가 비어있는 순서대로 저장 -> 이중구조 -> 인덱싱하는데 여러번 일을 수행함. + 데이터타입, 위치 체크

그러나, numpy Array는 한열로 저장하고, 데이터타입동일하기때문에 -> 인덱싱하는데 최소한의 일만 수행함.
-------------------------------------------------------------
strides (=pointer)
1칸에 4Byte, 1줄에 12Byte
-------------------------------------------------------------
loop연산속도
numpy vectorize > map function > list comprehonsion > plain forLoop
-------------------------------------------------------------

array([[ 0,  1,  2,  3],
       [ 4,  5,  6,  7],
       [ 8,  9, 10, 11]])

x[[True, True, False], [False, False, True, True]] # True인 행과 True인 열

-------------------------------------------------------------
axis
axis = 0 열마다
axis = 1 행마다
axis = None 전체

-------------------------------------------------------------
numpy 도움말 보기
1. np.info(np.sum) - 
2. np.lookfor('sum') - 문자열 포함된 모든 목록 찾아줌
-------------------------------------------------------------
?.shape
(x, y, z)
size, height, width
-------------------------------------------------------------
데이터 저장방식
대부분 C이나 간혹 포트란
c : 
1 2 3 4
5 6 7 8 
포트란 :
1 3 5 7
2 4 6 8
-------------------------------------------------------------
Multidimensional Arrays
ndarray
-------------------------------------------------------------
%whos ndarray # ndarray만 찾기 (numpy.ndarray)
-------------------------------------------------------------
uint16 (=unsigned )
-------------------------------------------------------------
영상, 이미지는 int16(for 256), 금융은 float64
-------------------------------------------------------------
ufunc (=universal Functions)

%time reduce(lambda x, y : x + y, range(100_000))
CPU times: user 12.7 ms, sys: 0 ns, total: 12.7 ms
Wall time: 12.2 ms
4999950000

%time np.add.reduce(np.arange(100_000))
CPU times: user 1.1 ms, sys: 0 ns, total: 1.1 ms
Wall time: 500 µs
4999950000

%time np.sum(np.arange(100_000))
CPU times: user 959 µs, sys: 311 µs, total: 1.27 ms
Wall time: 641 µs
4999950000

-------------------------------------------------------------
mean 평균
accumulate 누적합
-------------------------------------------------------------
차원끼리 연산하기위해서는 서로 모양이 같아야한다.
하지만 보정해주는 경우가 있는데 이를 활용한 기법이, broadcasting기법

# broadcasting

# 1.  
np.array([[1,2],[3,4]]) + 1

# 2. shape에 1만 있을경우. 크기 보정
np.array([[1,2],[3,4]]) + np.array([[4,5]])

# 3. 2와는 반대로
np.array([[1,2],[3,4]]) + np.array([[10],[10]])

# example
iris['petal_length'] + 10 # broadcasting
-------------------------------------------------------------
수동으로 맞추는방법 - 

1. reshape - 원본미접근, 모양기준, 2차로 변경되기도함.

# 수동으로 맞춰주는법
a = np.arange(10)
a = a.reshape(2, -1) # 모든 음수값은 가능하나 관례상 -1

2. resize - 원본접근, 갯수기준

3. ravel - view

4. flatten - copy
  
5. squeeze - 차원 축소

6. expand_dims - 차원 확대

7. newaxis - 
-------------------------------------------------------------
strides를 변경해도 가능
-------------------------------------------------------------
pickle
직렬화 기법
일반 텍스트가 아닌 데이터형을 유지한채 저장하는 방식
-------------------------------------------------------------
r_ : !callable
ix_ : callable
-------------------------------------------------------------
pandas 활용법 두가지
	- 1. EDA (Exploratory Data Analysis) 탐색적 데이터 분석
	- 2. 기계학습을 위한 전처리


-------------------------------------------------------------
dataFrame 2열이상
	- 인덱스와 헤더가 존재하는 
	- .values하면 numpy포맷으로 변경
	- 2차원
-------------------------------------------------------------
series 1열
	- .values하면 numpy포맷으로 변경
	- 1차원
-------------------------------------------------------------
열로 추출 - dictionary방식

b['사고년도']
-------------------------------------------------------------
.으로 접근.
dictionary방식 말고 (=data['column']) .방식도있음.
단, 특문이나 numpy의 키워드랑 겹치면안된다.
-------------------------------------------------------------
 (numpy syntax)
b.describe() # summary
b.describe().T #  열과 행 바꾸기 .T

-------------------------------------------------------------
데이터프레임 가져오면 하는것
1. .info()
2. describe() - include값이 기본적으로 숫자만 되어있으므로
-------------------------------------------------------------
loc는 이름으로
iloc는 순수 인덱스번호로
-------------------------------------------------------------
inplace - 그대로 적용을 시킬지의 여부(원본수정)
-------------------------------------------------------------
pandas에서는 index가 X축
-------------------------------------------------------------
# 컬럼추출방법 3가지

	# 1. series
	tips['tip'] 	

	# 2. dataFrame
	tips[['tip']] 

	# 3. 프로퍼티로접근
	tips.tip 
-------------------------------------------------------------
unique
	tips['day'].unique() # 서로다른 갯수
-------------------------------------------------------------
predicate함수

	boolean반환하는 함수
	bool이 왜 True|False 인데, 숫자 1과 0으로 취급되는가 ?
	상속받았는지 여부 확인하기.로 확인가능
	issubclass(bool, int)
-------------------------------------------------------------
시각화해서 보기 ( info, describe 보완 ) 

	mpg.boxplot()

-------------------------------------------------------------
상관계수 
data.corr()

# 색이 진하면 진할수록 음의 상관관계, 색이 옅을수록 양의 상관관계
sns.heatmap(mpg.corr()) # 색분포도로 데이터간 상관관계를 visualization화하여 보는 법
-------------------------------------------------------------
when import data

	1. head - 머리에서 데이터 추출

	2. tail - 바닥에서 데이터 추출

	3. sample - n개만큼 랜덤한 데이터 추출
-------------------------------------------------------------
graph그리기 
대상데이터.plot.원하는그래프형태()
-------------------------------------------------------------
기본적으로 세팅하는 라이브러리

	import numpy as np
	import matplotlib.pyplot as plt
	import pandas as pd
	import seaborn as sns
-------------------------------------------------------------
스타일을 바꾸게되면
	pandas가 plt에 의존하고있어서 pandas도 같이 바뀜
		plt.style.available # 사용가능한 스타일 목록조회
		plt.style.use('ggplot') # 사용하고싶은 스타일 세팅


	history
		from sadf import * # 편하긴하나 무겁.
		import matplotlib.pylab as plt # pylab이 가벼우나 공식홈페이지에서도 지양하는 방법
		import matplotlib.pyplot as plt # 결국 이걸로 사용
-------------------------------------------------------------
그래프수정하기 - State Machine기법 개념 이해해야함.

	plt.figure(figsize=(10, 5))
	plt.axes()
	plt.hist([1,2,1,2,3,4])
	plt.title('Title'); # 제목
	plt.xticks([1,2,3]); # x축 
	plt.yticks([1,3,5,7]); # y축
	plt.xlim([1,2]) # x범위 지정
	plt.ylim([1,2]) # y범위 지정
	plt.xlabel('xTicks Name') # x축 이름
	plt.ylabel('yTicks Name') # y축 이름

-------------------------------------------------------------

# 한글적용하기
	import matplotlib

	폰트리스트 확인
		fm = matplotlib.font_manager.FontManager()
		# fm.ttflist # 현재 컴퓨터에서 사용가능한 폰트리스트 확인
		# <Font 'Noto Sans CJK JP' (NotoSansCJK-Thin.ttc) normal normal 400 normal>

	폰트 적용
		plt.rcParams['font.family'] = 'Noto Sans CJK JP' # 한글 지원하는 폰트로 설정
	
-------------------------------------------------------------
%lsmagic # jupyter에서 지원하는 매직펑션 확인

%matplotlib notebook # 팝업처럼나옴, 물론 현재 os설정에 따라 달라지기도함.
%matplotlib inline # 기본값(=노잼)
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
