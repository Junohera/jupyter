{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_wine()\n",
    "data_ = pd.DataFrame(data.data, columns = data.feature_names)\n",
    "data_p = pd.DataFrame(data.target, columns=['target'])\n",
    "wine = pd.concat([data_, data_p], axis=1)\n",
    "wine = pd.concat([data_, data_p], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 오버피팅 방어\n",
    "# 가장 좋은 n개 선택하는 법 - 10개 데이터중에 가장 중요한 n개만 선택\n",
    "from sklearn.feature_selection import chi2, SelectKBest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "skb = SelectKBest(chi2, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.060000e+00, 5.640000e+00, 1.065000e+03],\n",
       "       [2.760000e+00, 4.380000e+00, 1.050000e+03],\n",
       "       [3.240000e+00, 5.680000e+00, 1.185000e+03],\n",
       "       [3.490000e+00, 7.800000e+00, 1.480000e+03],\n",
       "       [2.690000e+00, 4.320000e+00, 7.350000e+02],\n",
       "       [3.390000e+00, 6.750000e+00, 1.450000e+03],\n",
       "       [2.520000e+00, 5.250000e+00, 1.290000e+03],\n",
       "       [2.510000e+00, 5.050000e+00, 1.295000e+03],\n",
       "       [2.980000e+00, 5.200000e+00, 1.045000e+03],\n",
       "       [3.150000e+00, 7.220000e+00, 1.045000e+03],\n",
       "       [3.320000e+00, 5.750000e+00, 1.510000e+03],\n",
       "       [2.430000e+00, 5.000000e+00, 1.280000e+03],\n",
       "       [2.760000e+00, 5.600000e+00, 1.320000e+03],\n",
       "       [3.690000e+00, 5.400000e+00, 1.150000e+03],\n",
       "       [3.640000e+00, 7.500000e+00, 1.547000e+03],\n",
       "       [2.910000e+00, 7.300000e+00, 1.310000e+03],\n",
       "       [3.140000e+00, 6.200000e+00, 1.280000e+03],\n",
       "       [3.400000e+00, 6.600000e+00, 1.130000e+03],\n",
       "       [3.930000e+00, 8.700000e+00, 1.680000e+03],\n",
       "       [3.030000e+00, 5.100000e+00, 8.450000e+02],\n",
       "       [3.170000e+00, 5.650000e+00, 7.800000e+02],\n",
       "       [2.410000e+00, 4.500000e+00, 7.700000e+02],\n",
       "       [2.880000e+00, 3.800000e+00, 1.035000e+03],\n",
       "       [2.370000e+00, 3.930000e+00, 1.015000e+03],\n",
       "       [2.610000e+00, 3.520000e+00, 8.450000e+02],\n",
       "       [2.680000e+00, 3.580000e+00, 8.300000e+02],\n",
       "       [2.940000e+00, 4.800000e+00, 1.195000e+03],\n",
       "       [2.190000e+00, 3.950000e+00, 1.285000e+03],\n",
       "       [2.970000e+00, 4.500000e+00, 9.150000e+02],\n",
       "       [2.330000e+00, 4.700000e+00, 1.035000e+03],\n",
       "       [3.250000e+00, 5.700000e+00, 1.285000e+03],\n",
       "       [3.190000e+00, 6.900000e+00, 1.515000e+03],\n",
       "       [2.690000e+00, 3.840000e+00, 9.900000e+02],\n",
       "       [2.740000e+00, 5.400000e+00, 1.235000e+03],\n",
       "       [2.530000e+00, 4.200000e+00, 1.095000e+03],\n",
       "       [2.980000e+00, 5.100000e+00, 9.200000e+02],\n",
       "       [2.680000e+00, 4.600000e+00, 8.800000e+02],\n",
       "       [2.430000e+00, 4.250000e+00, 1.105000e+03],\n",
       "       [2.640000e+00, 3.700000e+00, 1.020000e+03],\n",
       "       [3.040000e+00, 5.100000e+00, 7.600000e+02],\n",
       "       [3.290000e+00, 6.130000e+00, 7.950000e+02],\n",
       "       [2.680000e+00, 4.280000e+00, 1.035000e+03],\n",
       "       [3.560000e+00, 5.430000e+00, 1.095000e+03],\n",
       "       [2.630000e+00, 4.360000e+00, 6.800000e+02],\n",
       "       [3.000000e+00, 5.040000e+00, 8.850000e+02],\n",
       "       [2.650000e+00, 5.240000e+00, 1.080000e+03],\n",
       "       [3.170000e+00, 4.900000e+00, 1.065000e+03],\n",
       "       [3.390000e+00, 6.100000e+00, 9.850000e+02],\n",
       "       [2.920000e+00, 6.200000e+00, 1.060000e+03],\n",
       "       [3.540000e+00, 8.900000e+00, 1.260000e+03],\n",
       "       [3.270000e+00, 7.200000e+00, 1.150000e+03],\n",
       "       [2.990000e+00, 5.600000e+00, 1.265000e+03],\n",
       "       [3.740000e+00, 7.050000e+00, 1.190000e+03],\n",
       "       [2.790000e+00, 6.300000e+00, 1.375000e+03],\n",
       "       [2.900000e+00, 5.850000e+00, 1.060000e+03],\n",
       "       [2.780000e+00, 6.250000e+00, 1.120000e+03],\n",
       "       [3.000000e+00, 6.380000e+00, 9.700000e+02],\n",
       "       [3.230000e+00, 6.000000e+00, 1.270000e+03],\n",
       "       [3.670000e+00, 6.800000e+00, 1.285000e+03],\n",
       "       [5.700000e-01, 1.950000e+00, 5.200000e+02],\n",
       "       [1.090000e+00, 3.270000e+00, 6.800000e+02],\n",
       "       [1.410000e+00, 5.750000e+00, 4.500000e+02],\n",
       "       [1.790000e+00, 3.800000e+00, 6.300000e+02],\n",
       "       [3.100000e+00, 4.450000e+00, 4.200000e+02],\n",
       "       [1.750000e+00, 2.950000e+00, 3.550000e+02],\n",
       "       [2.650000e+00, 4.600000e+00, 6.780000e+02],\n",
       "       [3.180000e+00, 5.300000e+00, 5.020000e+02],\n",
       "       [2.000000e+00, 4.680000e+00, 5.100000e+02],\n",
       "       [1.300000e+00, 3.170000e+00, 7.500000e+02],\n",
       "       [1.280000e+00, 2.850000e+00, 7.180000e+02],\n",
       "       [1.020000e+00, 3.050000e+00, 8.700000e+02],\n",
       "       [2.860000e+00, 3.380000e+00, 4.100000e+02],\n",
       "       [1.840000e+00, 3.740000e+00, 4.720000e+02],\n",
       "       [2.890000e+00, 3.350000e+00, 9.850000e+02],\n",
       "       [2.140000e+00, 3.210000e+00, 8.860000e+02],\n",
       "       [1.570000e+00, 3.800000e+00, 4.280000e+02],\n",
       "       [2.030000e+00, 4.600000e+00, 3.920000e+02],\n",
       "       [1.320000e+00, 2.650000e+00, 5.000000e+02],\n",
       "       [1.850000e+00, 3.400000e+00, 7.500000e+02],\n",
       "       [2.550000e+00, 2.570000e+00, 4.630000e+02],\n",
       "       [2.260000e+00, 2.500000e+00, 2.780000e+02],\n",
       "       [2.530000e+00, 3.900000e+00, 7.140000e+02],\n",
       "       [1.580000e+00, 2.200000e+00, 6.300000e+02],\n",
       "       [1.590000e+00, 4.800000e+00, 5.150000e+02],\n",
       "       [2.210000e+00, 3.050000e+00, 5.200000e+02],\n",
       "       [1.940000e+00, 2.620000e+00, 4.500000e+02],\n",
       "       [1.690000e+00, 2.450000e+00, 4.950000e+02],\n",
       "       [1.610000e+00, 2.600000e+00, 5.620000e+02],\n",
       "       [1.690000e+00, 2.800000e+00, 6.800000e+02],\n",
       "       [1.590000e+00, 1.740000e+00, 6.250000e+02],\n",
       "       [1.500000e+00, 2.400000e+00, 4.800000e+02],\n",
       "       [1.250000e+00, 3.600000e+00, 4.500000e+02],\n",
       "       [1.460000e+00, 3.050000e+00, 4.950000e+02],\n",
       "       [2.250000e+00, 2.150000e+00, 2.900000e+02],\n",
       "       [2.260000e+00, 3.250000e+00, 3.450000e+02],\n",
       "       [2.270000e+00, 2.600000e+00, 9.370000e+02],\n",
       "       [9.900000e-01, 2.500000e+00, 6.250000e+02],\n",
       "       [2.500000e+00, 2.900000e+00, 4.280000e+02],\n",
       "       [3.750000e+00, 4.500000e+00, 6.600000e+02],\n",
       "       [2.990000e+00, 2.300000e+00, 4.060000e+02],\n",
       "       [2.170000e+00, 3.300000e+00, 7.100000e+02],\n",
       "       [1.360000e+00, 2.450000e+00, 5.620000e+02],\n",
       "       [2.110000e+00, 2.800000e+00, 4.380000e+02],\n",
       "       [1.640000e+00, 2.060000e+00, 4.150000e+02],\n",
       "       [1.920000e+00, 2.940000e+00, 6.720000e+02],\n",
       "       [1.840000e+00, 2.700000e+00, 3.150000e+02],\n",
       "       [2.030000e+00, 3.400000e+00, 5.100000e+02],\n",
       "       [1.760000e+00, 3.300000e+00, 4.880000e+02],\n",
       "       [2.040000e+00, 2.700000e+00, 3.120000e+02],\n",
       "       [2.920000e+00, 2.650000e+00, 6.800000e+02],\n",
       "       [2.580000e+00, 2.900000e+00, 5.620000e+02],\n",
       "       [2.270000e+00, 2.000000e+00, 3.250000e+02],\n",
       "       [2.030000e+00, 3.800000e+00, 6.070000e+02],\n",
       "       [2.010000e+00, 3.080000e+00, 4.340000e+02],\n",
       "       [2.290000e+00, 2.900000e+00, 3.850000e+02],\n",
       "       [2.170000e+00, 1.900000e+00, 4.070000e+02],\n",
       "       [1.600000e+00, 1.950000e+00, 4.950000e+02],\n",
       "       [2.090000e+00, 2.060000e+00, 3.450000e+02],\n",
       "       [1.250000e+00, 3.400000e+00, 3.720000e+02],\n",
       "       [1.640000e+00, 1.280000e+00, 5.640000e+02],\n",
       "       [2.790000e+00, 3.250000e+00, 6.250000e+02],\n",
       "       [5.080000e+00, 6.000000e+00, 4.650000e+02],\n",
       "       [2.130000e+00, 2.080000e+00, 3.650000e+02],\n",
       "       [2.650000e+00, 2.600000e+00, 3.800000e+02],\n",
       "       [3.030000e+00, 2.800000e+00, 3.800000e+02],\n",
       "       [2.650000e+00, 2.760000e+00, 3.780000e+02],\n",
       "       [3.150000e+00, 3.940000e+00, 3.520000e+02],\n",
       "       [2.240000e+00, 3.000000e+00, 4.660000e+02],\n",
       "       [2.450000e+00, 2.120000e+00, 3.420000e+02],\n",
       "       [1.750000e+00, 2.600000e+00, 5.800000e+02],\n",
       "       [1.250000e+00, 4.100000e+00, 6.300000e+02],\n",
       "       [1.220000e+00, 5.400000e+00, 5.300000e+02],\n",
       "       [1.090000e+00, 5.700000e+00, 5.600000e+02],\n",
       "       [1.200000e+00, 5.000000e+00, 6.000000e+02],\n",
       "       [5.800000e-01, 5.450000e+00, 6.500000e+02],\n",
       "       [6.600000e-01, 7.100000e+00, 6.950000e+02],\n",
       "       [4.700000e-01, 3.850000e+00, 7.200000e+02],\n",
       "       [6.000000e-01, 5.000000e+00, 5.150000e+02],\n",
       "       [4.800000e-01, 5.700000e+00, 5.800000e+02],\n",
       "       [6.000000e-01, 4.920000e+00, 5.900000e+02],\n",
       "       [5.000000e-01, 4.600000e+00, 6.000000e+02],\n",
       "       [5.000000e-01, 5.600000e+00, 7.800000e+02],\n",
       "       [5.200000e-01, 4.350000e+00, 5.200000e+02],\n",
       "       [8.000000e-01, 4.400000e+00, 5.500000e+02],\n",
       "       [7.800000e-01, 8.210000e+00, 8.550000e+02],\n",
       "       [5.500000e-01, 4.000000e+00, 8.300000e+02],\n",
       "       [3.400000e-01, 4.900000e+00, 4.150000e+02],\n",
       "       [6.500000e-01, 7.650000e+00, 6.250000e+02],\n",
       "       [7.600000e-01, 8.420000e+00, 6.500000e+02],\n",
       "       [1.390000e+00, 9.400000e+00, 5.500000e+02],\n",
       "       [1.570000e+00, 8.600000e+00, 5.000000e+02],\n",
       "       [1.360000e+00, 1.080000e+01, 4.800000e+02],\n",
       "       [1.280000e+00, 7.100000e+00, 4.250000e+02],\n",
       "       [8.300000e-01, 1.052000e+01, 6.750000e+02],\n",
       "       [5.800000e-01, 7.600000e+00, 6.400000e+02],\n",
       "       [6.300000e-01, 7.900000e+00, 7.250000e+02],\n",
       "       [8.300000e-01, 9.010000e+00, 4.800000e+02],\n",
       "       [5.800000e-01, 7.500000e+00, 8.800000e+02],\n",
       "       [1.310000e+00, 1.300000e+01, 6.600000e+02],\n",
       "       [1.100000e+00, 1.175000e+01, 6.200000e+02],\n",
       "       [9.200000e-01, 7.650000e+00, 5.200000e+02],\n",
       "       [5.600000e-01, 5.880000e+00, 6.800000e+02],\n",
       "       [6.000000e-01, 5.580000e+00, 5.700000e+02],\n",
       "       [7.000000e-01, 5.280000e+00, 6.750000e+02],\n",
       "       [6.800000e-01, 9.580000e+00, 6.150000e+02],\n",
       "       [4.700000e-01, 6.620000e+00, 5.200000e+02],\n",
       "       [9.200000e-01, 1.068000e+01, 6.950000e+02],\n",
       "       [6.600000e-01, 1.026000e+01, 6.850000e+02],\n",
       "       [8.400000e-01, 8.660000e+00, 7.500000e+02],\n",
       "       [9.600000e-01, 8.500000e+00, 6.300000e+02],\n",
       "       [4.900000e-01, 5.500000e+00, 5.100000e+02],\n",
       "       [5.100000e-01, 9.899999e+00, 4.700000e+02],\n",
       "       [7.000000e-01, 9.700000e+00, 6.600000e+02],\n",
       "       [6.100000e-01, 7.700000e+00, 7.400000e+02],\n",
       "       [7.500000e-01, 7.300000e+00, 7.500000e+02],\n",
       "       [6.900000e-01, 1.020000e+01, 8.350000e+02],\n",
       "       [6.800000e-01, 9.300000e+00, 8.400000e+02],\n",
       "       [7.600000e-01, 9.200000e+00, 5.600000e+02]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skb.fit_transform(wine.iloc[:, :-1], wine['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score_func': <function sklearn.feature_selection.univariate_selection.chi2(X, y)>,\n",
       " 'k': 3,\n",
       " 'scores_': array([5.44549882e+00, 2.80686046e+01, 7.43380598e-01, 2.93836955e+01,\n",
       "        4.50263809e+01, 1.56230759e+01, 6.33343081e+01, 1.81548480e+00,\n",
       "        9.36828307e+00, 1.09016647e+02, 5.18253981e+00, 2.33898834e+01,\n",
       "        1.65400671e+04]),\n",
       " 'pvalues_': array([6.56938863e-02, 8.03489047e-07, 6.89567769e-01, 4.16304971e-07,\n",
       "        1.66972759e-10, 4.05034646e-04, 1.76656548e-14, 4.03433989e-01,\n",
       "        9.24066398e-03, 2.12488671e-24, 7.49248322e-02, 8.33587826e-06,\n",
       "        0.00000000e+00])}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(skb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE # recurcive  성능으로만 체크해서 가장 좋은것 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = RFE(LogisticRegression(), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ai39/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/ai39/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/ai39/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/ai39/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/ai39/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/ai39/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/ai39/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/ai39/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/ai39/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/ai39/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/ai39/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/ai39/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/ai39/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/ai39/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/ai39/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/ai39/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/ai39/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/ai39/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                 fit_intercept=True, intercept_scaling=1,\n",
       "                                 l1_ratio=None, max_iter=100,\n",
       "                                 multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                                 random_state=None, solver='warn', tol=0.0001,\n",
       "                                 verbose=0, warm_start=False),\n",
       "    n_features_to_select=5, step=1, verbose=0)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref.fit(wine.iloc[:,:-1], wine.target) # 가장 성능좋은 거 뽑을때"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'estimator': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                    intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                    multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                    random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                    warm_start=False),\n",
       " 'n_features_to_select': 5,\n",
       " 'step': 1,\n",
       " 'verbose': 0,\n",
       " 'estimator_': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                    intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                    multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                    random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                    warm_start=False),\n",
       " 'n_features_': 5,\n",
       " 'support_': array([False, False,  True, False, False, False,  True, False, False,\n",
       "         True,  True,  True, False]),\n",
       " 'ranking_': array([7, 3, 1, 2, 8, 6, 1, 5, 4, 1, 1, 1, 9])}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ai39/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/ai39/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/ai39/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/ai39/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/ai39/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/ai39/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/ai39/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/ai39/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/ai39/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/ai39/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/ai39/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/ai39/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/ai39/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/ai39/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/ai39/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/ai39/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/ai39/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/ai39/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 2.43    ,  3.06    ,  5.64    ,  1.04    ,  3.92    ],\n",
       "       [ 2.14    ,  2.76    ,  4.38    ,  1.05    ,  3.4     ],\n",
       "       [ 2.67    ,  3.24    ,  5.68    ,  1.03    ,  3.17    ],\n",
       "       [ 2.5     ,  3.49    ,  7.8     ,  0.86    ,  3.45    ],\n",
       "       [ 2.87    ,  2.69    ,  4.32    ,  1.04    ,  2.93    ],\n",
       "       [ 2.45    ,  3.39    ,  6.75    ,  1.05    ,  2.85    ],\n",
       "       [ 2.45    ,  2.52    ,  5.25    ,  1.02    ,  3.58    ],\n",
       "       [ 2.61    ,  2.51    ,  5.05    ,  1.06    ,  3.58    ],\n",
       "       [ 2.17    ,  2.98    ,  5.2     ,  1.08    ,  2.85    ],\n",
       "       [ 2.27    ,  3.15    ,  7.22    ,  1.01    ,  3.55    ],\n",
       "       [ 2.3     ,  3.32    ,  5.75    ,  1.25    ,  3.17    ],\n",
       "       [ 2.32    ,  2.43    ,  5.      ,  1.17    ,  2.82    ],\n",
       "       [ 2.41    ,  2.76    ,  5.6     ,  1.15    ,  2.9     ],\n",
       "       [ 2.39    ,  3.69    ,  5.4     ,  1.25    ,  2.73    ],\n",
       "       [ 2.38    ,  3.64    ,  7.5     ,  1.2     ,  3.      ],\n",
       "       [ 2.7     ,  2.91    ,  7.3     ,  1.28    ,  2.88    ],\n",
       "       [ 2.72    ,  3.14    ,  6.2     ,  1.07    ,  2.65    ],\n",
       "       [ 2.62    ,  3.4     ,  6.6     ,  1.13    ,  2.57    ],\n",
       "       [ 2.48    ,  3.93    ,  8.7     ,  1.23    ,  2.82    ],\n",
       "       [ 2.56    ,  3.03    ,  5.1     ,  0.96    ,  3.36    ],\n",
       "       [ 2.28    ,  3.17    ,  5.65    ,  1.09    ,  3.71    ],\n",
       "       [ 2.65    ,  2.41    ,  4.5     ,  1.03    ,  3.52    ],\n",
       "       [ 2.36    ,  2.88    ,  3.8     ,  1.11    ,  4.      ],\n",
       "       [ 2.52    ,  2.37    ,  3.93    ,  1.09    ,  3.63    ],\n",
       "       [ 2.61    ,  2.61    ,  3.52    ,  1.12    ,  3.82    ],\n",
       "       [ 3.22    ,  2.68    ,  3.58    ,  1.13    ,  3.2     ],\n",
       "       [ 2.62    ,  2.94    ,  4.8     ,  0.92    ,  3.22    ],\n",
       "       [ 2.14    ,  2.19    ,  3.95    ,  1.02    ,  2.77    ],\n",
       "       [ 2.8     ,  2.97    ,  4.5     ,  1.25    ,  3.4     ],\n",
       "       [ 2.21    ,  2.33    ,  4.7     ,  1.04    ,  3.59    ],\n",
       "       [ 2.7     ,  3.25    ,  5.7     ,  1.19    ,  2.71    ],\n",
       "       [ 2.36    ,  3.19    ,  6.9     ,  1.09    ,  2.88    ],\n",
       "       [ 2.36    ,  2.69    ,  3.84    ,  1.23    ,  2.87    ],\n",
       "       [ 2.7     ,  2.74    ,  5.4     ,  1.25    ,  3.      ],\n",
       "       [ 2.65    ,  2.53    ,  4.2     ,  1.1     ,  2.87    ],\n",
       "       [ 2.41    ,  2.98    ,  5.1     ,  1.04    ,  3.47    ],\n",
       "       [ 2.84    ,  2.68    ,  4.6     ,  1.09    ,  2.78    ],\n",
       "       [ 2.55    ,  2.43    ,  4.25    ,  1.12    ,  2.51    ],\n",
       "       [ 2.1     ,  2.64    ,  3.7     ,  1.18    ,  2.69    ],\n",
       "       [ 2.51    ,  3.04    ,  5.1     ,  0.89    ,  3.53    ],\n",
       "       [ 2.31    ,  3.29    ,  6.13    ,  0.95    ,  3.38    ],\n",
       "       [ 2.12    ,  2.68    ,  4.28    ,  0.91    ,  3.      ],\n",
       "       [ 2.59    ,  3.56    ,  5.43    ,  0.88    ,  3.56    ],\n",
       "       [ 2.29    ,  2.63    ,  4.36    ,  0.82    ,  3.      ],\n",
       "       [ 2.1     ,  3.      ,  5.04    ,  0.88    ,  3.35    ],\n",
       "       [ 2.44    ,  2.65    ,  5.24    ,  0.87    ,  3.33    ],\n",
       "       [ 2.28    ,  3.17    ,  4.9     ,  1.04    ,  3.44    ],\n",
       "       [ 2.12    ,  3.39    ,  6.1     ,  0.91    ,  3.33    ],\n",
       "       [ 2.4     ,  2.92    ,  6.2     ,  1.07    ,  2.75    ],\n",
       "       [ 2.27    ,  3.54    ,  8.9     ,  1.12    ,  3.1     ],\n",
       "       [ 2.04    ,  3.27    ,  7.2     ,  1.12    ,  2.91    ],\n",
       "       [ 2.6     ,  2.99    ,  5.6     ,  1.24    ,  3.37    ],\n",
       "       [ 2.42    ,  3.74    ,  7.05    ,  1.01    ,  3.26    ],\n",
       "       [ 2.68    ,  2.79    ,  6.3     ,  1.13    ,  2.93    ],\n",
       "       [ 2.25    ,  2.9     ,  5.85    ,  0.92    ,  3.2     ],\n",
       "       [ 2.46    ,  2.78    ,  6.25    ,  0.98    ,  3.03    ],\n",
       "       [ 2.3     ,  3.      ,  6.38    ,  0.94    ,  3.31    ],\n",
       "       [ 2.68    ,  3.23    ,  6.      ,  1.07    ,  2.84    ],\n",
       "       [ 2.5     ,  3.67    ,  6.8     ,  0.89    ,  2.87    ],\n",
       "       [ 1.36    ,  0.57    ,  1.95    ,  1.05    ,  1.82    ],\n",
       "       [ 2.28    ,  1.09    ,  3.27    ,  1.25    ,  1.67    ],\n",
       "       [ 2.02    ,  1.41    ,  5.75    ,  0.98    ,  1.59    ],\n",
       "       [ 1.92    ,  1.79    ,  3.8     ,  1.23    ,  2.46    ],\n",
       "       [ 2.16    ,  3.1     ,  4.45    ,  1.22    ,  2.87    ],\n",
       "       [ 2.53    ,  1.75    ,  2.95    ,  1.45    ,  2.23    ],\n",
       "       [ 2.56    ,  2.65    ,  4.6     ,  1.19    ,  2.3     ],\n",
       "       [ 1.7     ,  3.18    ,  5.3     ,  1.12    ,  3.18    ],\n",
       "       [ 1.92    ,  2.      ,  4.68    ,  1.12    ,  3.48    ],\n",
       "       [ 2.36    ,  1.3     ,  3.17    ,  1.02    ,  1.93    ],\n",
       "       [ 1.75    ,  1.28    ,  2.85    ,  1.28    ,  3.07    ],\n",
       "       [ 2.21    ,  1.02    ,  3.05    ,  0.906   ,  1.82    ],\n",
       "       [ 2.67    ,  2.86    ,  3.38    ,  1.36    ,  3.16    ],\n",
       "       [ 2.24    ,  1.84    ,  3.74    ,  0.98    ,  2.78    ],\n",
       "       [ 2.6     ,  2.89    ,  3.35    ,  1.31    ,  3.5     ],\n",
       "       [ 2.3     ,  2.14    ,  3.21    ,  0.99    ,  3.13    ],\n",
       "       [ 1.92    ,  1.57    ,  3.8     ,  1.23    ,  2.14    ],\n",
       "       [ 1.71    ,  2.03    ,  4.6     ,  1.19    ,  2.48    ],\n",
       "       [ 2.23    ,  1.32    ,  2.65    ,  0.96    ,  2.52    ],\n",
       "       [ 1.95    ,  1.85    ,  3.4     ,  1.06    ,  2.31    ],\n",
       "       [ 2.4     ,  2.55    ,  2.57    ,  1.19    ,  3.13    ],\n",
       "       [ 2.      ,  2.26    ,  2.5     ,  1.38    ,  3.12    ],\n",
       "       [ 2.2     ,  2.53    ,  3.9     ,  1.16    ,  3.14    ],\n",
       "       [ 2.51    ,  1.58    ,  2.2     ,  1.31    ,  2.72    ],\n",
       "       [ 2.32    ,  1.59    ,  4.8     ,  0.84    ,  2.01    ],\n",
       "       [ 2.58    ,  2.21    ,  3.05    ,  0.79    ,  3.08    ],\n",
       "       [ 2.24    ,  1.94    ,  2.62    ,  1.23    ,  3.16    ],\n",
       "       [ 2.31    ,  1.69    ,  2.45    ,  1.33    ,  2.26    ],\n",
       "       [ 2.62    ,  1.61    ,  2.6     ,  1.36    ,  3.21    ],\n",
       "       [ 2.46    ,  1.69    ,  2.8     ,  1.      ,  2.75    ],\n",
       "       [ 2.3     ,  1.59    ,  1.74    ,  1.07    ,  3.21    ],\n",
       "       [ 2.32    ,  1.5     ,  2.4     ,  1.08    ,  2.27    ],\n",
       "       [ 2.42    ,  1.25    ,  3.6     ,  1.05    ,  2.65    ],\n",
       "       [ 2.26    ,  1.46    ,  3.05    ,  0.96    ,  2.06    ],\n",
       "       [ 2.22    ,  2.25    ,  2.15    ,  1.15    ,  3.3     ],\n",
       "       [ 2.28    ,  2.26    ,  3.25    ,  1.16    ,  2.96    ],\n",
       "       [ 2.2     ,  2.27    ,  2.6     ,  1.16    ,  2.63    ],\n",
       "       [ 2.74    ,  0.99    ,  2.5     ,  0.95    ,  2.26    ],\n",
       "       [ 1.98    ,  2.5     ,  2.9     ,  1.23    ,  2.74    ],\n",
       "       [ 2.1     ,  3.75    ,  4.5     ,  1.04    ,  2.77    ],\n",
       "       [ 2.21    ,  2.99    ,  2.3     ,  1.42    ,  2.83    ],\n",
       "       [ 1.7     ,  2.17    ,  3.3     ,  1.27    ,  2.96    ],\n",
       "       [ 1.9     ,  1.36    ,  2.45    ,  1.04    ,  2.77    ],\n",
       "       [ 2.46    ,  2.11    ,  2.8     ,  0.8     ,  3.38    ],\n",
       "       [ 1.88    ,  1.64    ,  2.06    ,  0.94    ,  2.44    ],\n",
       "       [ 1.98    ,  1.92    ,  2.94    ,  1.04    ,  3.57    ],\n",
       "       [ 2.27    ,  1.84    ,  2.7     ,  0.86    ,  3.3     ],\n",
       "       [ 2.12    ,  2.03    ,  3.4     ,  1.      ,  3.17    ],\n",
       "       [ 2.28    ,  1.76    ,  3.3     ,  0.88    ,  2.42    ],\n",
       "       [ 1.94    ,  2.04    ,  2.7     ,  0.86    ,  3.02    ],\n",
       "       [ 2.7     ,  2.92    ,  2.65    ,  0.96    ,  3.26    ],\n",
       "       [ 1.82    ,  2.58    ,  2.9     ,  0.75    ,  2.81    ],\n",
       "       [ 2.17    ,  2.27    ,  2.      ,  0.9     ,  2.78    ],\n",
       "       [ 2.92    ,  2.03    ,  3.8     ,  1.23    ,  2.5     ],\n",
       "       [ 2.5     ,  2.01    ,  3.08    ,  1.1     ,  2.31    ],\n",
       "       [ 2.5     ,  2.29    ,  2.9     ,  0.93    ,  3.19    ],\n",
       "       [ 2.2     ,  2.17    ,  1.9     ,  1.71    ,  2.87    ],\n",
       "       [ 1.99    ,  1.6     ,  1.95    ,  0.95    ,  3.33    ],\n",
       "       [ 2.19    ,  2.09    ,  2.06    ,  1.06    ,  2.96    ],\n",
       "       [ 1.98    ,  1.25    ,  3.4     ,  0.7     ,  2.12    ],\n",
       "       [ 2.      ,  1.64    ,  1.28    ,  0.93    ,  3.05    ],\n",
       "       [ 2.42    ,  2.79    ,  3.25    ,  0.8     ,  3.39    ],\n",
       "       [ 3.23    ,  5.08    ,  6.      ,  0.93    ,  3.69    ],\n",
       "       [ 2.73    ,  2.13    ,  2.08    ,  0.92    ,  3.12    ],\n",
       "       [ 2.13    ,  2.65    ,  2.6     ,  0.73    ,  3.1     ],\n",
       "       [ 2.39    ,  3.03    ,  2.8     ,  0.75    ,  3.64    ],\n",
       "       [ 2.17    ,  2.65    ,  2.76    ,  0.86    ,  3.28    ],\n",
       "       [ 2.29    ,  3.15    ,  3.94    ,  0.69    ,  2.84    ],\n",
       "       [ 2.78    ,  2.24    ,  3.      ,  0.97    ,  2.44    ],\n",
       "       [ 2.3     ,  2.45    ,  2.12    ,  0.89    ,  2.78    ],\n",
       "       [ 2.38    ,  1.75    ,  2.6     ,  0.79    ,  2.57    ],\n",
       "       [ 2.32    ,  1.25    ,  4.1     ,  0.76    ,  1.29    ],\n",
       "       [ 2.4     ,  1.22    ,  5.4     ,  0.74    ,  1.42    ],\n",
       "       [ 2.4     ,  1.09    ,  5.7     ,  0.66    ,  1.36    ],\n",
       "       [ 2.36    ,  1.2     ,  5.      ,  0.78    ,  1.29    ],\n",
       "       [ 2.25    ,  0.58    ,  5.45    ,  0.75    ,  1.51    ],\n",
       "       [ 2.2     ,  0.66    ,  7.1     ,  0.73    ,  1.58    ],\n",
       "       [ 2.54    ,  0.47    ,  3.85    ,  0.75    ,  1.27    ],\n",
       "       [ 2.64    ,  0.6     ,  5.      ,  0.82    ,  1.69    ],\n",
       "       [ 2.19    ,  0.48    ,  5.7     ,  0.81    ,  1.82    ],\n",
       "       [ 2.61    ,  0.6     ,  4.92    ,  0.89    ,  2.15    ],\n",
       "       [ 2.7     ,  0.5     ,  4.6     ,  0.77    ,  2.31    ],\n",
       "       [ 2.35    ,  0.5     ,  5.6     ,  0.7     ,  2.47    ],\n",
       "       [ 2.72    ,  0.52    ,  4.35    ,  0.89    ,  2.06    ],\n",
       "       [ 2.35    ,  0.8     ,  4.4     ,  0.91    ,  2.05    ],\n",
       "       [ 2.2     ,  0.78    ,  8.21    ,  0.65    ,  2.      ],\n",
       "       [ 2.15    ,  0.55    ,  4.      ,  0.6     ,  1.68    ],\n",
       "       [ 2.23    ,  0.34    ,  4.9     ,  0.58    ,  1.33    ],\n",
       "       [ 2.48    ,  0.65    ,  7.65    ,  0.54    ,  1.86    ],\n",
       "       [ 2.38    ,  0.76    ,  8.42    ,  0.55    ,  1.62    ],\n",
       "       [ 2.36    ,  1.39    ,  9.4     ,  0.57    ,  1.33    ],\n",
       "       [ 2.62    ,  1.57    ,  8.6     ,  0.59    ,  1.3     ],\n",
       "       [ 2.48    ,  1.36    , 10.8     ,  0.48    ,  1.47    ],\n",
       "       [ 2.75    ,  1.28    ,  7.1     ,  0.61    ,  1.33    ],\n",
       "       [ 2.28    ,  0.83    , 10.52    ,  0.56    ,  1.51    ],\n",
       "       [ 2.1     ,  0.58    ,  7.6     ,  0.58    ,  1.55    ],\n",
       "       [ 2.32    ,  0.63    ,  7.9     ,  0.6     ,  1.48    ],\n",
       "       [ 2.38    ,  0.83    ,  9.01    ,  0.57    ,  1.64    ],\n",
       "       [ 2.64    ,  0.58    ,  7.5     ,  0.67    ,  1.73    ],\n",
       "       [ 2.7     ,  1.31    , 13.      ,  0.57    ,  1.96    ],\n",
       "       [ 2.64    ,  1.1     , 11.75    ,  0.57    ,  1.78    ],\n",
       "       [ 2.38    ,  0.92    ,  7.65    ,  0.56    ,  1.58    ],\n",
       "       [ 2.54    ,  0.56    ,  5.88    ,  0.96    ,  1.82    ],\n",
       "       [ 2.58    ,  0.6     ,  5.58    ,  0.87    ,  2.11    ],\n",
       "       [ 2.35    ,  0.7     ,  5.28    ,  0.68    ,  1.75    ],\n",
       "       [ 2.3     ,  0.68    ,  9.58    ,  0.7     ,  1.68    ],\n",
       "       [ 2.26    ,  0.47    ,  6.62    ,  0.78    ,  1.75    ],\n",
       "       [ 2.6     ,  0.92    , 10.68    ,  0.85    ,  1.56    ],\n",
       "       [ 2.3     ,  0.66    , 10.26    ,  0.72    ,  1.75    ],\n",
       "       [ 2.69    ,  0.84    ,  8.66    ,  0.74    ,  1.8     ],\n",
       "       [ 2.86    ,  0.96    ,  8.5     ,  0.67    ,  1.92    ],\n",
       "       [ 2.32    ,  0.49    ,  5.5     ,  0.66    ,  1.83    ],\n",
       "       [ 2.28    ,  0.51    ,  9.899999,  0.57    ,  1.63    ],\n",
       "       [ 2.48    ,  0.7     ,  9.7     ,  0.62    ,  1.71    ],\n",
       "       [ 2.45    ,  0.61    ,  7.7     ,  0.64    ,  1.74    ],\n",
       "       [ 2.48    ,  0.75    ,  7.3     ,  0.7     ,  1.56    ],\n",
       "       [ 2.26    ,  0.69    , 10.2     ,  0.59    ,  1.56    ],\n",
       "       [ 2.37    ,  0.68    ,  9.3     ,  0.6     ,  1.62    ],\n",
       "       [ 2.74    ,  0.76    ,  9.2     ,  0.61    ,  1.6     ]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref.fit_transform(wine.iloc[:,:-1], wine.target) # 가장 좋은 값까지 뽑을때"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'estimator': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                    intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                    multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                    random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                    warm_start=False),\n",
       " 'n_features_to_select': 5,\n",
       " 'step': 1,\n",
       " 'verbose': 0,\n",
       " 'estimator_': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                    intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                    multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                    random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                    warm_start=False),\n",
       " 'n_features_': 5,\n",
       " 'support_': array([False, False,  True, False, False, False,  True, False, False,\n",
       "         True,  True,  True, False]),\n",
       " 'ranking_': array([7, 3, 1, 2, 8, 6, 1, 5, 4, 1, 1, 1, 9])}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ash', 'flavanoids', 'color_intensity', 'hue',\n",
       "       'od280/od315_of_diluted_wines'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.columns[:-1][ref.support_] # 성능으로만 체크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
